{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLQpeQ7gXzxy"
   },
   "source": [
    "# Pro-social Dialog, Allen-AI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ki_8Vs_3bh81"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_prosocial = pd.read_json('train.json', lines = True)\n",
    "df_test = pd.read_json('test.json', lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "id": "8XOpANy8Ihyp",
    "outputId": "20879a22-b2f5-45da-fbb1-fd5e9d88cc80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>rots</th>\n",
       "      <th>safety_label</th>\n",
       "      <th>safety_annotations</th>\n",
       "      <th>safety_annotation_reasons</th>\n",
       "      <th>source</th>\n",
       "      <th>etc</th>\n",
       "      <th>dialogue_id</th>\n",
       "      <th>response_id</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I tried a bit of shadowboxing today. Got one g...</td>\n",
       "      <td>This isn't a joke about black people, right? I...</td>\n",
       "      <td>[It's not right to think black people deserve ...</td>\n",
       "      <td>__needs_caution__</td>\n",
       "      <td>[needs caution, needs caution, needs caution]</td>\n",
       "      <td>[It's rude to make jokes about the color of pe...</td>\n",
       "      <td>sbic</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You're right, it isn't funny. Finding enjoymen...</td>\n",
       "      <td>I am glad that you agree. Joking about abusing...</td>\n",
       "      <td>[It's not right to think black people deserve ...</td>\n",
       "      <td>__casual__</td>\n",
       "      <td>[casual, casual, casual]</td>\n",
       "      <td>[The speaker admits they spoke inappropriately...</td>\n",
       "      <td>sbic</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did I tell you how I used to poke holes in con...</td>\n",
       "      <td>That's a pretty low down thing to do.</td>\n",
       "      <td>[It's immoral to poke holes in condoms.]</td>\n",
       "      <td>__needs_intervention__</td>\n",
       "      <td>[needs caution, needs intervention, needs inte...</td>\n",
       "      <td>[Speaker admits to committing a seriously wron...</td>\n",
       "      <td>socialchemistry</td>\n",
       "      <td>reddit/confessions/bsajnv</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I wanted to prank others like that</td>\n",
       "      <td>You should not poke holes in condoms. You coul...</td>\n",
       "      <td>[It's harmful to tamper with other peoples con...</td>\n",
       "      <td>__needs_intervention__</td>\n",
       "      <td>[needs caution, needs intervention, needs inte...</td>\n",
       "      <td>[Speaker explains why they did the act., They ...</td>\n",
       "      <td>socialchemistry</td>\n",
       "      <td>reddit/confessions/bsajnv</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's harmless. I doesn't hurt anyone. I just w...</td>\n",
       "      <td>You're not thinking. How do you conclude expos...</td>\n",
       "      <td>[It's normal for people to be alarmed by an un...</td>\n",
       "      <td>__needs_intervention__</td>\n",
       "      <td>[needs caution, needs intervention, needs inte...</td>\n",
       "      <td>[Speaker doesn't see why what they did was wro...</td>\n",
       "      <td>socialchemistry</td>\n",
       "      <td>reddit/confessions/bsajnv</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  I tried a bit of shadowboxing today. Got one g...   \n",
       "1  You're right, it isn't funny. Finding enjoymen...   \n",
       "2  Did I tell you how I used to poke holes in con...   \n",
       "3                 I wanted to prank others like that   \n",
       "4  It's harmless. I doesn't hurt anyone. I just w...   \n",
       "\n",
       "                                            response  \\\n",
       "0  This isn't a joke about black people, right? I...   \n",
       "1  I am glad that you agree. Joking about abusing...   \n",
       "2              That's a pretty low down thing to do.   \n",
       "3  You should not poke holes in condoms. You coul...   \n",
       "4  You're not thinking. How do you conclude expos...   \n",
       "\n",
       "                                                rots            safety_label  \\\n",
       "0  [It's not right to think black people deserve ...       __needs_caution__   \n",
       "1  [It's not right to think black people deserve ...              __casual__   \n",
       "2           [It's immoral to poke holes in condoms.]  __needs_intervention__   \n",
       "3  [It's harmful to tamper with other peoples con...  __needs_intervention__   \n",
       "4  [It's normal for people to be alarmed by an un...  __needs_intervention__   \n",
       "\n",
       "                                  safety_annotations  \\\n",
       "0      [needs caution, needs caution, needs caution]   \n",
       "1                           [casual, casual, casual]   \n",
       "2  [needs caution, needs intervention, needs inte...   \n",
       "3  [needs caution, needs intervention, needs inte...   \n",
       "4  [needs caution, needs intervention, needs inte...   \n",
       "\n",
       "                           safety_annotation_reasons           source  \\\n",
       "0  [It's rude to make jokes about the color of pe...             sbic   \n",
       "1  [The speaker admits they spoke inappropriately...             sbic   \n",
       "2  [Speaker admits to committing a seriously wron...  socialchemistry   \n",
       "3  [Speaker explains why they did the act., They ...  socialchemistry   \n",
       "4  [Speaker doesn't see why what they did was wro...  socialchemistry   \n",
       "\n",
       "                         etc  dialogue_id  response_id  episode_done  \n",
       "0                                       0            0         False  \n",
       "1                                       0            1          True  \n",
       "2  reddit/confessions/bsajnv            1            0         False  \n",
       "3  reddit/confessions/bsajnv            1            1         False  \n",
       "4  reddit/confessions/bsajnv            1            2          True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prosocial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the length of cotext using a violon plot:\n",
    "import seaborn as sb\n",
    "\n",
    "df_prosocial['context_len']=[len(item) for item in df_prosocial['context']]\n",
    "sb.violinplot(df_prosocial['context_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RG5B4rBZgu6G",
    "outputId": "e999c848-0f5f-47e2-b2a2-d89309642f41"
   },
   "outputs": [],
   "source": [
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsfCLhdEIa_5",
    "outputId": "18724e43-ddc0-4784-dd17-68ffeb7a69dd"
   },
   "outputs": [],
   "source": [
    "#how many turns there are (eposode_done = True shows end of the turn)?\n",
    "# len(df_prosocial[df_prosocial['episode_done']==False]),len(df_prosocial[df_prosocial['episode_done']==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDUMqERSI9jQ",
    "outputId": "4c03aa94-d533-4aa5-89cf-68898c81d9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__casual__',\n",
       " '__needs_caution__',\n",
       " '__needs_intervention__',\n",
       " '__possibly_needs_caution__',\n",
       " '__probably_needs_caution__'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many classes there are:\n",
    "set(df_prosocial[df_prosocial['episode_done']==True]['safety_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'__needs_caution__': 50493,\n",
       "         '__casual__': 20690,\n",
       "         '__needs_intervention__': 14605,\n",
       "         '__possibly_needs_caution__': 16458,\n",
       "         '__probably_needs_caution__': 17990})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the number of sample in each class\n",
    "from collections import Counter\n",
    "Counter(df_prosocial.safety_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynMl8dtUftj9"
   },
   "source": [
    "# Classification using Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-TFdoQ67fyO-"
   },
   "outputs": [],
   "source": [
    "#get only the context, response, and the label columns\n",
    "data = df_prosocial[['context','response', 'safety_label']]\n",
    "data_test = df_test[['context', 'response', 'safety_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### give context to each sample to improve classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2lvhqXUGRzP",
    "outputId": "d02cb230-01bc-48ba-942b-679eb5a1b1b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1655832/956490412.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['context'].astype(str)+' '+data['response']\n"
     ]
    }
   ],
   "source": [
    "data['text'] = data['context'].astype(str)+' '+data['response']\n",
    "df_test['text'] = df_test['context'].astype(str)+' '+df_test['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revert to only include the context without responses\n",
    "# data['text'] = data['context']\n",
    "# data_test['text'] = data_test['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lWs1sGv8nhqL"
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"safety_label\":\"labels\"})\n",
    "testset = data_test.rename(columns={\"safety_label\":\"labels\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bhAYKvmkSVj"
   },
   "source": [
    "### Subsample 10 % of the data -- (next, try on all data when we have resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CH1koJx8oPnb",
    "outputId": "9f52a1a0-86ca-42ba-b744-b40299de2da1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18035, 120236)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.sample(frac = .15, replace = False, random_state = 123456789)\n",
    "len(df), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nkC_3_fJ7C8P"
   },
   "outputs": [],
   "source": [
    "# megering the cautious class to \"bully\" class, and convert the problem to a binary classification\n",
    "# df['labels'] = df['labels'].replace(['__needs_caution__','__needs_intervention__','__probably_needs_caution__','__possibly_needs_caution__' ], 'bully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jHDCTB98RCa",
    "outputId": "deb42c34-3c94-4bfd-ae9a-629d5271ef1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'__needs_caution__': 7580,\n",
       "         '__casual__': 3123,\n",
       "         '__needs_intervention__': 2251,\n",
       "         '__probably_needs_caution__': 2643,\n",
       "         '__possibly_needs_caution__': 2438})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJiJN-AsuuwN"
   },
   "source": [
    "# Prepare data and merge labels and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NXrLWiGBuzEC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class prepareDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings, labels):\n",
    "    self.encodings = encodings\n",
    "    self.labels = labels\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()} #why the encoding object gives the key directly but then val should be sent to torch.tensor ?\n",
    "    item['labels'] = torch.tensor(self.labels[idx])\n",
    "    return item\n",
    "\n",
    "  def __get_labels__(self, idx):\n",
    "    return torch.tensor(self.labels[idx])\n",
    "\n",
    "  def get_labels(self):\n",
    "    return self.labels\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "def encode_tags(labels, encodings):\n",
    "  #make an empty list to return at the end of this function\n",
    "  encoded_labels = []\n",
    "  #reading documents labels and their offset from extracted labels and given encoding input\n",
    "  for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "    #create an empty array of -100\n",
    "    doc_end_labels = np.ones(len(doc_offset), dtype = int)* -100\n",
    "    arr_offset = np.array(doc_offset)\n",
    "\n",
    "    #can only get documents with len of max MAX_LEN; if the len is bigger, only get to the MAX_LEN of those docuemnts and the rest is -100\n",
    "    #@Amin: but these are the labels. when does it take care of the input to not have len bigger than max_len?\n",
    "    try:\n",
    "      doc_end_labels[0:len(doc_labels)] = doc_labels\n",
    "    except:\n",
    "      doc_end_labels[0:MAX_LEN] = doc_labels\n",
    "\n",
    "    #add the current encoded labels to the previouse list of encoded_labels\n",
    "    encoded_labels.append(doc_end_labels.tolist())\n",
    "  return encoded_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRtJRBBHQCNP"
   },
   "source": [
    "## Get the tokenizer from AutiTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "782c841989ef4268bcc1ab327d98a1fc",
      "ed77c58ff2a441c9babe26320823aaf5",
      "b085f769eb924d5b8041e4a9cd13f356",
      "15b9ca1c3d094b94900d668762cad341",
      "0167867c7c0c4639ad9b6691b70b165a",
      "6f10887089fc452c963b22e2c6583ba9",
      "7f0491717e8b4976bb1a672be2964c4d",
      "5e44b051eb1e4043bb8642e3dffedf72",
      "b96d4a4dfe6a4349b076d168b1ce75c3",
      "0afb29e62a49444983f005706036c80a",
      "c6096e29a9f8488b9191258b9b565235",
      "1ea0b1bf9fd045a09d3128482ebe517b",
      "46d96161fc37443a82290a2135f7949c",
      "1309c025f74b4bedb25845edef69f4c6",
      "75f9b53b9af14371a5df2fe04e6518be",
      "db3a628c00184181a24a63e4debaa59f",
      "a36fcca0cdba428da7f005f033549d37",
      "94b84670fd8f4bb88b03a7958a3c44dd",
      "7fb86d2e82734178bc1693f71d999ef6",
      "66cee6ff2b5640239a42e47ec3906fa1",
      "e21ac0ee07584e13b076b947917a068e",
      "9be50ab4a01643e9b2058f75b7214c98",
      "439ed6c21e914f96b723273a77a0ca51",
      "77d59503b6244dd490e22eb74847630c",
      "1634891ebe3a4ff7af9650524a522f66",
      "f1517aa5e93f426394c327753f4add0c",
      "76d94e1dda2d433cb15a163c9f9c6e09",
      "b1e4b7aea89c46a7b70e3e8697e7a176",
      "a5473b94edc74a679a85f5fca6f41882",
      "b43b89c0370944889604dd768221c0e1",
      "b977d4dfc86d45849d1bde1062f779ff",
      "e06691ed9bb1440cb8bdfee1d031b51b",
      "d1d28394dc9549d891242364227fdea1",
      "28c9c5bab1fc4d959f0557ff909c6ca1",
      "43432f8a70c44a92ae61da19d08a58a4",
      "19f6c01b98b14a10aa74d76c2c3de8b8",
      "60ae0f8d99b94668a0e5555843c9fed9",
      "317a42a173144a31993c04b50c368b3f",
      "efaa6e25b82a4d1b8df1df5aec1c330a",
      "8cec12ffe5fd4c3d8898f2426b9d35af",
      "508a0972d56e4345909cf8995116bc3f",
      "7d28e8748c2d42799dc24fa3a5878de0",
      "1ceae7b0507f4fba9a8f670432e9fb2b",
      "06962d9faa44487aa5074ae1b281e431"
     ]
    },
    "id": "vX-eLzXQQGW9",
    "outputId": "d6b57711-aea2-4502-e03c-795948563c4f"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "#testing distilbert instead of bert-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QoJXpEgqWieE"
   },
   "source": [
    "### Subsample a balanced dataset based on labels.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ddarD7OkY4Ej"
   },
   "outputs": [],
   "source": [
    "df_labels = df['labels'].tolist()\n",
    "df_input = df['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YULoaM2dPFyq"
   },
   "source": [
    "## Downsampling the dataset -- first, try it without sampling!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Cz4d7hZyPFMT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11255"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler()\n",
    "df_in, df_labels = rus.fit_resample(df, df['labels'].tolist())\n",
    "df_input = df_in['text'].tolist()\n",
    "len(df_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'__casual__': 2251,\n",
       "         '__needs_caution__': 2251,\n",
       "         '__needs_intervention__': 2251,\n",
       "         '__possibly_needs_caution__': 2251,\n",
       "         '__probably_needs_caution__': 2251})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_in['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnUX2dVsf8SL"
   },
   "source": [
    "### split train to train and valiation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "c9ox0_w5f_kg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "doc_set, doc_val, labels, labels_val = train_test_split(df_input, df_labels, test_size = .1, random_state = 123456789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GXcKkQGYmRE"
   },
   "source": [
    "### Tokenize the train set and valiation set, the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bJY3h1RqXoiq"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "inputs = tokenizer(doc_set, truncation=True,  padding='max_length',max_length = MAX_LEN, return_offsets_mapping=True)\n",
    "inputs_val =tokenizer(doc_val, truncation=True,  padding='max_length',max_length = MAX_LEN, return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LovcAXA-ZCZL"
   },
   "source": [
    "# Prepare dataset for the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-yTMD5eXdcZ"
   },
   "outputs": [],
   "source": [
    "#this is for token classificaiton, and not sequence classification.\n",
    "# labels = encode_tags(labels,inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYnlkdR1Lo9F"
   },
   "source": [
    "# Load the pre-trained BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXvcWn7uLbRj",
    "outputId": "2b383ff2-9439-471a-cf99-7895d68a70af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#load the pre-trained BERT model\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "MAX_LEN = 512\n",
    "# num_class = 5\n",
    "num_class = 2\n",
    "# Add two layers of softmax -- > I think we added one?\n",
    "class SequenceClassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SequenceClassification, self).__init__()\n",
    "        #self.fc1 = torch.nn.Linear(MAX_LEN*768, num_class) since we only need CLS, given it is a classification problem, we do not need to have MAX_LEN here :\n",
    "        self.l1 = torch.nn.Linear(768, 512)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.dropout1 = torch.nn.Dropout(0.10)\n",
    "\n",
    "\n",
    "        #layer 2:\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.dropout2 = torch.nn.Dropout(.1)\n",
    "\n",
    "\n",
    "        # layer 3:\n",
    "        self.fc = torch.nn.Linear(256, num_class)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.dropout3 = torch.nn.Dropout(.1)\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = model(input_ids, attention_mask,return_dict=False)\n",
    "        pooled_output = outputs[1] # get the pooled output 1 (i.e., CLS token)\n",
    "        pooled_output = self.dropout1(self.activation1(self.l1(pooled_output)))\n",
    "        pooled_output = self.dropout2(self.activation2(self.l2(pooled_output)))\n",
    "        pooled_output = self.dropout3(self.softmax(self.fc(pooled_output)))\n",
    "\n",
    "        # x = self.softmax(self.fc1(torch.relu(pooled_output)))\n",
    "\n",
    "        # pooled_output = self.dropout1(pooled_output)\n",
    "        # output1 = self.l1(pooled_output)\n",
    "        # input2 = self.dropout2(output1)\n",
    "        # output2 = self.activation2(input2)\n",
    "        # output2 = self.dropout2(output2)\n",
    "        # x = self.softmax(output2)\n",
    "        return pooled_output\n",
    "\n",
    "# Use the SoftmaxLayers model\n",
    "classification_model = SequenceClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGFsbuGksryk",
    "outputId": "06ca70e5-484b-4d10-bc2a-ac2570d4d044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassification(\n",
      "  (l1): Linear(in_features=768, out_features=512, bias=True)\n",
      "  (activation1): ReLU()\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (l2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (activation2): ReLU()\n",
      "  (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (dropout3): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8iTBZQoRT3-2"
   },
   "outputs": [],
   "source": [
    "tag2id = {\n",
    "      '__casual__' : 0,\n",
    "      '__needs_caution__' : 1,\n",
    "      '__needs_intervention__' :2,\n",
    "      '__possibly_needs_caution__':3,\n",
    "      '__probably_needs_caution__':4\n",
    "\n",
    "  }\n",
    "\n",
    "# ids for testing the model on a binary classification (i.e., casual and bully classes)\n",
    "# tag2id = {\n",
    "#       '__casual__' : 0,\n",
    "#       'bully' : 1\n",
    "#   }\n",
    "\n",
    "id2tag = {v:k for k,v in tag2id.items()} #when and how do we want to use this id2tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUFZ_-tfyos4",
    "outputId": "2545f4c5-63e6-444e-831a-c4936b135f4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '__casual__',\n",
       " 1: '__needs_caution__',\n",
       " 2: '__needs_intervention__',\n",
       " 3: '__possibly_needs_caution__',\n",
       " 4: '__probably_needs_caution__'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2FLAUCsjVPs",
    "outputId": "46879f9f-876f-4075-cc1b-1a279e5d9ef9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the string labels to ids\n",
    "int_labels = [tag2id[tag] for tag in labels]\n",
    "set(int_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Sjomv0V5hW__"
   },
   "outputs": [],
   "source": [
    "labeles_val_int = [tag2id[tag] for tag in labels_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "oqTiYnINaW6E"
   },
   "outputs": [],
   "source": [
    "#@ this prepare dataset only take care of the labels? do we use the input as returned by the tokenizer?\n",
    "train_dataset = prepareDataset(inputs, int_labels)\n",
    "val_dataset = prepareDataset(inputs_val, labeles_val_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing BertModel: ['distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'vocab_projector.weight', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'pooler.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.self.query.bias', 'embeddings.word_embeddings.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.output.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#load the pre-trained BERT model and fine-tune the data on a pre-trained model.\n",
    "model_name = 'distilbert-base-cased'\n",
    "model = BertModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#using hugging face model instead of ours:\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-cased\", num_labels=5, id2label=id2tag, label2id=tag2id, from_tf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "CXoZKdmqY16B"
   },
   "outputs": [],
   "source": [
    "# pip install torchsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Plk-k6e7nmUC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/tljh/user/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIlEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIMw-qQOu0MU",
    "outputId": "0f34ad25-d295-40e9-fe79-06359ad2a3c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2045, 3: 2012, 2: 2021, 4: 2027, 0: 2024})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(int_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "Taqan0HMP__G",
    "outputId": "f3dfe521-c611-4d3e-e9a9-27369ca567b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1, batch 100/8216, Loss: 0.20358751371502876\n",
      "Epoch 0/1, batch 200/8216, Loss: 0.20169284299016\n",
      "Epoch 0/1, batch 300/8216, Loss: 0.20144096240401269\n",
      "Epoch 0/1, batch 400/8216, Loss: 0.20159250393509864\n",
      "Epoch 0/1, batch 500/8216, Loss: 0.20176831349730492\n",
      "Epoch 0/1, batch 600/8216, Loss: 0.20141353502869605\n",
      "Epoch 0/1, batch 700/8216, Loss: 0.20136508628726005\n",
      "Epoch 0/1, batch 800/8216, Loss: 0.20143188580870627\n",
      "Epoch 0/1, batch 900/8216, Loss: 0.20108332514762878\n",
      "Epoch 0/1, batch 1000/8216, Loss: 0.20207090839743613\n",
      "Epoch 0/1, batch 1100/8216, Loss: 0.20136445447802542\n",
      "Epoch 0/1, batch 1200/8216, Loss: 0.20190103828907013\n",
      "Epoch 0/1, batch 1300/8216, Loss: 0.20148227602243424\n",
      "Epoch 0/1, batch 1400/8216, Loss: 0.20121277183294295\n",
      "Epoch 0/1, batch 1500/8216, Loss: 0.20132773533463477\n",
      "Epoch 0/1, batch 1600/8216, Loss: 0.2013779279589653\n",
      "Epoch 0/1, batch 1700/8216, Loss: 0.2015802749991417\n",
      "Epoch 0/1, batch 1800/8216, Loss: 0.2011352077126503\n",
      "Epoch 0/1, batch 1900/8216, Loss: 0.2017877931892872\n",
      "Epoch 0/1, batch 2000/8216, Loss: 0.20149684950709343\n",
      "Epoch 0/1, batch 2100/8216, Loss: 0.2012310041487217\n",
      "Epoch 0/1, batch 2200/8216, Loss: 0.20182465329766275\n",
      "Epoch 0/1, batch 2300/8216, Loss: 0.20110610142350197\n",
      "Epoch 0/1, batch 2400/8216, Loss: 0.20174552977085114\n",
      "Epoch 0/1, batch 2500/8216, Loss: 0.201744444668293\n",
      "Epoch 0/1, batch 2600/8216, Loss: 0.2014834488928318\n",
      "Epoch 0/1, batch 2700/8216, Loss: 0.2010493777692318\n",
      "Epoch 0/1, batch 2800/8216, Loss: 0.201577158421278\n",
      "Epoch 0/1, batch 2900/8216, Loss: 0.20174016907811165\n",
      "Epoch 0/1, batch 3000/8216, Loss: 0.20247209429740906\n",
      "Epoch 0/1, batch 3100/8216, Loss: 0.2018802557885647\n",
      "Epoch 0/1, batch 3200/8216, Loss: 0.20184312969446183\n",
      "Epoch 0/1, batch 3300/8216, Loss: 0.20163566261529922\n",
      "Epoch 0/1, batch 3400/8216, Loss: 0.20175162076950073\n",
      "Epoch 0/1, batch 3500/8216, Loss: 0.2019901293516159\n",
      "Epoch 0/1, batch 3600/8216, Loss: 0.20170171201229095\n",
      "Epoch 0/1, batch 3700/8216, Loss: 0.2014935591816902\n",
      "Epoch 0/1, batch 3800/8216, Loss: 0.20177705019712447\n",
      "Epoch 0/1, batch 3900/8216, Loss: 0.2015424309670925\n",
      "Epoch 0/1, batch 4000/8216, Loss: 0.2011297619342804\n",
      "Epoch 0/1, batch 4100/8216, Loss: 0.201837936937809\n",
      "Epoch 0/1, batch 4200/8216, Loss: 0.20146007895469664\n",
      "Epoch 0/1, batch 4300/8216, Loss: 0.20157361507415772\n",
      "Epoch 0/1, batch 4400/8216, Loss: 0.2016119082272053\n",
      "Epoch 0/1, batch 4500/8216, Loss: 0.20190008237957954\n",
      "Epoch 0/1, batch 4600/8216, Loss: 0.2010596840083599\n",
      "Epoch 0/1, batch 4700/8216, Loss: 0.20193832367658615\n",
      "Epoch 0/1, batch 4800/8216, Loss: 0.20122726649045944\n",
      "Epoch 0/1, batch 4900/8216, Loss: 0.20187077224254607\n",
      "Epoch 0/1, batch 5000/8216, Loss: 0.20163142874836923\n",
      "Epoch 0/1, batch 5100/8216, Loss: 0.20211141780018807\n",
      "Epoch 0/1, batch 5200/8216, Loss: 0.20139455735683442\n",
      "Epoch 0/1, batch 5300/8216, Loss: 0.20193504840135573\n",
      "Epoch 0/1, batch 5400/8216, Loss: 0.20105146393179893\n",
      "Epoch 0/1, batch 5500/8216, Loss: 0.20169362872838975\n",
      "Epoch 0/1, batch 5600/8216, Loss: 0.2012677063047886\n",
      "Epoch 0/1, batch 5700/8216, Loss: 0.20174824997782706\n",
      "Epoch 0/1, batch 5800/8216, Loss: 0.20158906251192094\n",
      "Epoch 0/1, batch 5900/8216, Loss: 0.20180079326033593\n",
      "Epoch 0/1, batch 6000/8216, Loss: 0.20119249805808068\n",
      "Epoch 0/1, batch 6100/8216, Loss: 0.20161425933241844\n",
      "Epoch 0/1, batch 6200/8216, Loss: 0.2011234964430332\n",
      "Epoch 0/1, batch 6300/8216, Loss: 0.2017525166273117\n",
      "Epoch 0/1, batch 6400/8216, Loss: 0.20094667583703996\n",
      "Epoch 0/1, batch 6500/8216, Loss: 0.2014998558163643\n",
      "Epoch 0/1, batch 6600/8216, Loss: 0.20127492070198058\n",
      "Epoch 0/1, batch 6700/8216, Loss: 0.2015737374126911\n",
      "Epoch 0/1, batch 6800/8216, Loss: 0.2010207025706768\n",
      "Epoch 0/1, batch 6900/8216, Loss: 0.2015503291785717\n",
      "Epoch 0/1, batch 7000/8216, Loss: 0.2022629714012146\n",
      "Epoch 0/1, batch 7100/8216, Loss: 0.20132318437099456\n",
      "Epoch 0/1, batch 7200/8216, Loss: 0.20149750709533693\n",
      "Epoch 0/1, batch 7300/8216, Loss: 0.20173875361680985\n",
      "Epoch 0/1, batch 7400/8216, Loss: 0.20135627761483194\n",
      "Epoch 0/1, batch 7500/8216, Loss: 0.20125044032931327\n",
      "Epoch 0/1, batch 7600/8216, Loss: 0.2014726196229458\n",
      "Epoch 0/1, batch 7700/8216, Loss: 0.20121529683470726\n",
      "Epoch 0/1, batch 7800/8216, Loss: 0.20134626761078833\n",
      "Epoch 0/1, batch 7900/8216, Loss: 0.20125671327114106\n",
      "Epoch 0/1, batch 8000/8216, Loss: 0.20131369099020957\n",
      "Epoch 0/1, batch 8100/8216, Loss: 0.2012349283695221\n",
      "Epoch 0/1, batch 8200/8216, Loss: 0.20147474646568297\n",
      "Epoch 0 finished with train loss of 0.2015354879501529 and validation loss of 0.20132350459743825\n",
      "Epoch 1/1, batch 100/8216, Loss: 0.20404093995690345\n",
      "Epoch 1/1, batch 200/8216, Loss: 0.2015489362180233\n",
      "Epoch 1/1, batch 300/8216, Loss: 0.20149245217442513\n",
      "Epoch 1/1, batch 400/8216, Loss: 0.2016890336573124\n",
      "Epoch 1/1, batch 500/8216, Loss: 0.20196722820401192\n",
      "Epoch 1/1, batch 600/8216, Loss: 0.2016187699139118\n",
      "Epoch 1/1, batch 700/8216, Loss: 0.20108258366584777\n",
      "Epoch 1/1, batch 800/8216, Loss: 0.20140527248382567\n",
      "Epoch 1/1, batch 900/8216, Loss: 0.2013632632791996\n",
      "Epoch 1/1, batch 1000/8216, Loss: 0.2018108581006527\n",
      "Epoch 1/1, batch 1100/8216, Loss: 0.20187174826860427\n",
      "Epoch 1/1, batch 1200/8216, Loss: 0.20173057466745375\n",
      "Epoch 1/1, batch 1300/8216, Loss: 0.20122918531298636\n",
      "Epoch 1/1, batch 1400/8216, Loss: 0.20138781771063805\n",
      "Epoch 1/1, batch 1500/8216, Loss: 0.20143821701407433\n",
      "Epoch 1/1, batch 1600/8216, Loss: 0.20150729075074195\n",
      "Epoch 1/1, batch 1700/8216, Loss: 0.20157711923122407\n",
      "Epoch 1/1, batch 1800/8216, Loss: 0.20137470230460167\n",
      "Epoch 1/1, batch 1900/8216, Loss: 0.20155975356698036\n",
      "Epoch 1/1, batch 2000/8216, Loss: 0.20172878608107567\n",
      "Epoch 1/1, batch 2100/8216, Loss: 0.2011910730600357\n",
      "Epoch 1/1, batch 2200/8216, Loss: 0.2018369308114052\n",
      "Epoch 1/1, batch 2300/8216, Loss: 0.20170967280864716\n",
      "Epoch 1/1, batch 2400/8216, Loss: 0.20137897461652757\n",
      "Epoch 1/1, batch 2500/8216, Loss: 0.20168807357549667\n",
      "Epoch 1/1, batch 2600/8216, Loss: 0.20139873459935187\n",
      "Epoch 1/1, batch 2700/8216, Loss: 0.2011771807074547\n",
      "Epoch 1/1, batch 2800/8216, Loss: 0.20134325176477433\n",
      "Epoch 1/1, batch 2900/8216, Loss: 0.20146640241146088\n",
      "Epoch 1/1, batch 3000/8216, Loss: 0.20156919240951537\n",
      "Epoch 1/1, batch 3100/8216, Loss: 0.20128491953015326\n",
      "Epoch 1/1, batch 3200/8216, Loss: 0.20173326268792152\n",
      "Epoch 1/1, batch 3300/8216, Loss: 0.20136508122086524\n",
      "Epoch 1/1, batch 3400/8216, Loss: 0.20135391741991043\n",
      "Epoch 1/1, batch 3500/8216, Loss: 0.20157195374369621\n",
      "Epoch 1/1, batch 3600/8216, Loss: 0.2015332445502281\n",
      "Epoch 1/1, batch 3700/8216, Loss: 0.20203773006796838\n",
      "Epoch 1/1, batch 3800/8216, Loss: 0.20073109984397888\n",
      "Epoch 1/1, batch 3900/8216, Loss: 0.20141359239816667\n",
      "Epoch 1/1, batch 4000/8216, Loss: 0.20205685779452323\n",
      "Epoch 1/1, batch 4100/8216, Loss: 0.2011281295120716\n",
      "Epoch 1/1, batch 4200/8216, Loss: 0.20131155952811242\n",
      "Epoch 1/1, batch 4300/8216, Loss: 0.2014848054945469\n",
      "Epoch 1/1, batch 4400/8216, Loss: 0.2017043237388134\n",
      "Epoch 1/1, batch 4500/8216, Loss: 0.20111620008945466\n",
      "Epoch 1/1, batch 4600/8216, Loss: 0.2010042804479599\n",
      "Epoch 1/1, batch 4700/8216, Loss: 0.20163173586130143\n",
      "Epoch 1/1, batch 4800/8216, Loss: 0.20201303228735923\n",
      "Epoch 1/1, batch 4900/8216, Loss: 0.20141361340880393\n",
      "Epoch 1/1, batch 5000/8216, Loss: 0.2017383973300457\n",
      "Epoch 1/1, batch 5100/8216, Loss: 0.201591160595417\n",
      "Epoch 1/1, batch 5200/8216, Loss: 0.20155997917056084\n",
      "Epoch 1/1, batch 5300/8216, Loss: 0.20147346436977387\n",
      "Epoch 1/1, batch 5400/8216, Loss: 0.2012532350420952\n",
      "Epoch 1/1, batch 5500/8216, Loss: 0.20136329889297486\n",
      "Epoch 1/1, batch 5600/8216, Loss: 0.20226162821054458\n",
      "Epoch 1/1, batch 5700/8216, Loss: 0.20157303676009178\n",
      "Epoch 1/1, batch 5800/8216, Loss: 0.20164631336927413\n",
      "Epoch 1/1, batch 5900/8216, Loss: 0.2013630074262619\n",
      "Epoch 1/1, batch 6000/8216, Loss: 0.20194822207093238\n",
      "Epoch 1/1, batch 6100/8216, Loss: 0.20161377817392348\n",
      "Epoch 1/1, batch 6200/8216, Loss: 0.20146238312125206\n",
      "Epoch 1/1, batch 6300/8216, Loss: 0.20142000362277032\n",
      "Epoch 1/1, batch 6400/8216, Loss: 0.20151143953204154\n",
      "Epoch 1/1, batch 6500/8216, Loss: 0.2016381412744522\n",
      "Epoch 1/1, batch 6600/8216, Loss: 0.2018479272723198\n",
      "Epoch 1/1, batch 6700/8216, Loss: 0.20161457762122154\n",
      "Epoch 1/1, batch 6800/8216, Loss: 0.200981065928936\n",
      "Epoch 1/1, batch 6900/8216, Loss: 0.20146140411496163\n",
      "Epoch 1/1, batch 7000/8216, Loss: 0.20168913036584854\n",
      "Epoch 1/1, batch 7100/8216, Loss: 0.20125313147902488\n",
      "Epoch 1/1, batch 7200/8216, Loss: 0.20160710513591767\n",
      "Epoch 1/1, batch 7300/8216, Loss: 0.20117541268467903\n",
      "Epoch 1/1, batch 7400/8216, Loss: 0.20118803307414054\n",
      "Epoch 1/1, batch 7500/8216, Loss: 0.20133918315172195\n",
      "Epoch 1/1, batch 7600/8216, Loss: 0.20160095721483232\n",
      "Epoch 1/1, batch 7700/8216, Loss: 0.20151713803410531\n",
      "Epoch 1/1, batch 7800/8216, Loss: 0.20133248329162598\n",
      "Epoch 1/1, batch 7900/8216, Loss: 0.20208608523011207\n",
      "Epoch 1/1, batch 8000/8216, Loss: 0.20175869271159172\n",
      "Epoch 1/1, batch 8100/8216, Loss: 0.2012118722498417\n",
      "Epoch 1/1, batch 8200/8216, Loss: 0.202079948335886\n",
      "Epoch 1 finished with train loss of 0.2015264265406097 and validation loss of 0.20145091971000992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fine-tuning the model\n",
    "import torch\n",
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "\n",
    "#use CPU if the GPU is not avaiable\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if not torch.cuda.is_available():\n",
    "  logging.warning('GPY is not available. The modeing is being trained on CPU!')\n",
    "\n",
    "#preapre the model for training\n",
    "# model.config.id2label = id2tag\n",
    "model.to(device)\n",
    "model.train()\n",
    "#DO WE ALSO PUT THE MODEL FOR FINED TUNNING ON THE TRAIN PHASE AND THE BERT MODEL ITESELF?\n",
    "classification_model.to(device)\n",
    "classification_model.train()\n",
    "\n",
    "BSIZE = 8#batch size\n",
    "#preparing the data for PyTorch (does it mean to only convert it to batches?)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BSIZE, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BSIZE, sampler = ImbalancedDatasetSampler(train_dataset), shuffle=False)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BSIZE, sampler = ImbalancedDatasetSampler(val_dataset), shuffle=False)\n",
    "#set the optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "#set the criterion to compute error\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "#print the performance metrics over the training phase every iteration_reset=100\n",
    "iteration_reset = 100\n",
    "\n",
    "'''max of epochs. Change this responsibily. Higher values for epochs can cause overfitting.\n",
    "'''\n",
    "MAX_EPOCH = 2\n",
    "\n",
    "#main loop for epochs\n",
    "for epoch in range(MAX_EPOCH):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    loss_sum = 0.0\n",
    "\n",
    "    #batch training loop\n",
    "    for i,batch in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = classification_model(input_ids, attention_mask=attention_mask)[0]\n",
    "        # loss = outputs[0]\n",
    "        # loss = criterion(outputs.view(-1, tokenizer.vocab_size),labels.view(-1))\n",
    "        loss  = criterion(outputs,labels)\n",
    "        loss_sum += loss.to('cpu').detach().numpy()\n",
    "        train_loss += loss.to('cpu').detach().numpy()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        #printing loss\n",
    "        if i% iteration_reset == 0 and i>0:\n",
    "            print('Epoch {0}/{1}, batch {2}/{3}, Loss: {4}'.format(epoch,MAX_EPOCH-1,i,len(train_loader),\n",
    "                                                                   loss_sum/(iteration_reset*BSIZE)))\n",
    "            loss_sum = 0\n",
    "    #compute model performance during training, and after each epoch:\n",
    "    model.eval() #put the model to the val phase; in other words, turn off the training phase for this model\n",
    "    classification_model.eval()\n",
    "    with torch.no_grad():\n",
    "      for i, batch in enumerate(val_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = classification_model(input_ids, attention_mask = attention_mask)\n",
    "        loss = criterion(outputs[0], labels)\n",
    "        val_loss +=loss.to('cpu').detach().numpy()\n",
    "    print('Epoch {0} finished with train loss of {1} and validation loss of {2}'.format(epoch, train_loss/(BSIZE*len(train_loader)), val_loss/(BSIZE*len(val_loader))))\n",
    "    model.train() #put the model to the train phase..\n",
    "    classification_model.train()\n",
    "\n",
    "model.eval()\n",
    "classification_model.eval() #finally, we set off the training and put the model into validation for prediction use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.save_pretrained('classification_prosocial_finetuned_distilbert-base-cased',from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model.\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"classification_prosocial_finetuned_distilbert-base-cased\", from_tf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjB50-C6uQ5d",
    "outputId": "8c7a8a81-d33c-46cb-ac37-1e9bbb9ac660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished with train loss of 0.2015264265406097 and validation loss of 0.20145091971000992\n"
     ]
    }
   ],
   "source": [
    "print('Epoch {0} finished with train loss of {1} and validation loss of {2}'.format(epoch, train_loss/(BSIZE*len(train_loader)), val_loss/(BSIZE*len(val_loader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LD_cNLvTnvFe",
    "outputId": "18f93f19-6b54-4eb1-d21d-76469aad75db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0535,  0.1878,  0.0765,  0.0595,  0.0479],\n",
       "        [-0.0461,  0.1807,  0.0341,  0.0656,  0.0566],\n",
       "        [-0.0408,  0.1574,  0.0410,  0.0662,  0.0637],\n",
       "        [-0.0720,  0.2017,  0.0259,  0.0758,  0.0496],\n",
       "        [-0.0481,  0.1889,  0.0401,  0.0750,  0.0644],\n",
       "        [-0.0692,  0.1807,  0.0185,  0.0900,  0.0663],\n",
       "        [-0.0436,  0.1791,  0.0269,  0.0672,  0.0676]], device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6JDqsNKpXVQ",
    "outputId": "fa936ece-2db2-47fe-87a5-4e38838f30ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 1, 3, 0, 4, 3], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvRY02EVcaa9",
    "outputId": "2ce9e5e9-bda4-44a4-c2c8-175f72f5581b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQeCNnvkDja3"
   },
   "outputs": [],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "  for i, batch in enumerate(val_loader):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n",
    "    loss = outputs.logits\n",
    "    val_loss +=loss.to('cpu').detach().numpy()\n",
    "print('Epoch {0} finished with train loss of {1} and validation loss of {}'.format(epoch, train_loss/(BSIZE*len(train_loader))), val_loss/(BSIZE*len(val_loader)))\n",
    "model.train() #put the model to the train phase.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM-qrN7Xm6uo"
   },
   "source": [
    "### Compute performance after tranining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset['text'] =testset['context'].astype(str)+' '+testset['response'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "lOifwIsCp57P",
    "outputId": "db5bb3d1-629a-4cc1-ee4c-e61ffa6f0f11"
   },
   "outputs": [],
   "source": [
    "# MAX_LEN = 512\n",
    "doc_test_set = testset['text'].tolist()\n",
    "labels_test_set = testset['labels'].tolist()\n",
    "int_labels_test_set = [tag2id[tag] for tag in labels_test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trDIRHP4-lLv"
   },
   "source": [
    "#### prepare the test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "b69j847cm4_G"
   },
   "outputs": [],
   "source": [
    "# TEST BLOCK\n",
    "inputs_ids_test = tokenizer.encode_plus(doc_test_set[0])\n",
    "inputs_ids_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(classification_model(inputs_ids_test['input_ids'].to(device), attention_mask = inputs_ids_test['attention_mask'].to(device))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "jAtS4curtxRH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST BLOCK\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "classification_model(inputs_ids_test['input_ids'].to(device), attention_mask = inputs_ids_test['attention_mask'].to(device))\n",
    "# classification_model(inputs_ids_test['input_ids'].to(device), attention_mask = inputs_ids_test['attention_mask'].to(device)).config\n",
    "torch.argmax(classification_model(inputs_ids_test['input_ids'].to(device), attention_mask = inputs_ids_test['attention_mask'].to(device))[0] ,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0456,  0.1853,  0.0559,  0.0605,  0.0449]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model(inputs_ids_test['input_ids'].to(device), attention_mask = inputs_ids_test['attention_mask'].to(device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fo_y6dam_qm-"
   },
   "source": [
    "### Run the classification model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "lB1ndk0Uh4vI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25029"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. tokenize the test set, run the classification, get outputs, and append the results to later compute confusion matrix\n",
    "test_res = []\n",
    "for item in doc_test_set:\n",
    "  inputs_ids_test = tokenizer.encode_plus(item, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "  tests_output = torch.argmax(classification_model(inputs_ids_test['input_ids'].to(device), attention_mask = inputs_ids_test['attention_mask'].to(device))[0] ,dim=1).item()\n",
    "  test_res.append(tests_output)\n",
    "len(test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C87x1Db4_jwV"
   },
   "source": [
    "# Run the performance metric on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "-3et4SR7j8Yk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(int_labels_test_set, test_res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0167867c7c0c4639ad9b6691b70b165a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06962d9faa44487aa5074ae1b281e431": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0afb29e62a49444983f005706036c80a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1309c025f74b4bedb25845edef69f4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7fb86d2e82734178bc1693f71d999ef6",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66cee6ff2b5640239a42e47ec3906fa1",
      "value": 570
     }
    },
    "15b9ca1c3d094b94900d668762cad341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0afb29e62a49444983f005706036c80a",
      "placeholder": "",
      "style": "IPY_MODEL_c6096e29a9f8488b9191258b9b565235",
      "value": " 29.0/29.0 [00:00&lt;00:00, 847B/s]"
     }
    },
    "1634891ebe3a4ff7af9650524a522f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b43b89c0370944889604dd768221c0e1",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b977d4dfc86d45849d1bde1062f779ff",
      "value": 213450
     }
    },
    "19f6c01b98b14a10aa74d76c2c3de8b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_508a0972d56e4345909cf8995116bc3f",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d28e8748c2d42799dc24fa3a5878de0",
      "value": 435797
     }
    },
    "1ad61d3612a64ef9b8ab23e1e9d9b808": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ceae7b0507f4fba9a8f670432e9fb2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ea0b1bf9fd045a09d3128482ebe517b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46d96161fc37443a82290a2135f7949c",
       "IPY_MODEL_1309c025f74b4bedb25845edef69f4c6",
       "IPY_MODEL_75f9b53b9af14371a5df2fe04e6518be"
      ],
      "layout": "IPY_MODEL_db3a628c00184181a24a63e4debaa59f"
     }
    },
    "28c9c5bab1fc4d959f0557ff909c6ca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43432f8a70c44a92ae61da19d08a58a4",
       "IPY_MODEL_19f6c01b98b14a10aa74d76c2c3de8b8",
       "IPY_MODEL_60ae0f8d99b94668a0e5555843c9fed9"
      ],
      "layout": "IPY_MODEL_317a42a173144a31993c04b50c368b3f"
     }
    },
    "30870c47fba04429b3fc3d3efc02b897": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "317a42a173144a31993c04b50c368b3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35049b5472914614a70a4d037baee119": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4209d93661214168b7ace4dad9a72c5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43432f8a70c44a92ae61da19d08a58a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efaa6e25b82a4d1b8df1df5aec1c330a",
      "placeholder": "",
      "style": "IPY_MODEL_8cec12ffe5fd4c3d8898f2426b9d35af",
      "value": "Downloading ()/main/tokenizer.json: 100%"
     }
    },
    "439ed6c21e914f96b723273a77a0ca51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77d59503b6244dd490e22eb74847630c",
       "IPY_MODEL_1634891ebe3a4ff7af9650524a522f66",
       "IPY_MODEL_f1517aa5e93f426394c327753f4add0c"
      ],
      "layout": "IPY_MODEL_76d94e1dda2d433cb15a163c9f9c6e09"
     }
    },
    "46d96161fc37443a82290a2135f7949c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a36fcca0cdba428da7f005f033549d37",
      "placeholder": "",
      "style": "IPY_MODEL_94b84670fd8f4bb88b03a7958a3c44dd",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "508a0972d56e4345909cf8995116bc3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55ff8f2830a34fbc93be9d779c07e7e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e44b051eb1e4043bb8642e3dffedf72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f4e2dfdc9654446be174f32fa8d4d3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60ae0f8d99b94668a0e5555843c9fed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ceae7b0507f4fba9a8f670432e9fb2b",
      "placeholder": "",
      "style": "IPY_MODEL_06962d9faa44487aa5074ae1b281e431",
      "value": " 436k/436k [00:00&lt;00:00, 6.66MB/s]"
     }
    },
    "66cee6ff2b5640239a42e47ec3906fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f10887089fc452c963b22e2c6583ba9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75f9b53b9af14371a5df2fe04e6518be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e21ac0ee07584e13b076b947917a068e",
      "placeholder": "",
      "style": "IPY_MODEL_9be50ab4a01643e9b2058f75b7214c98",
      "value": " 570/570 [00:00&lt;00:00, 13.8kB/s]"
     }
    },
    "76d94e1dda2d433cb15a163c9f9c6e09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77d59503b6244dd490e22eb74847630c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1e4b7aea89c46a7b70e3e8697e7a176",
      "placeholder": "",
      "style": "IPY_MODEL_a5473b94edc74a679a85f5fca6f41882",
      "value": "Downloading ()solve/main/vocab.txt: 100%"
     }
    },
    "782c841989ef4268bcc1ab327d98a1fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed77c58ff2a441c9babe26320823aaf5",
       "IPY_MODEL_b085f769eb924d5b8041e4a9cd13f356",
       "IPY_MODEL_15b9ca1c3d094b94900d668762cad341"
      ],
      "layout": "IPY_MODEL_0167867c7c0c4639ad9b6691b70b165a"
     }
    },
    "7d28e8748c2d42799dc24fa3a5878de0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f0491717e8b4976bb1a672be2964c4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fb86d2e82734178bc1693f71d999ef6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8181a2c7eff049a3985b0d770cb58117": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4c34787373e41bcaddfb089accb2d99",
      "placeholder": "",
      "style": "IPY_MODEL_b8d2240e2f7b43819e7b160ab6801442",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "8a7d6755fa214a00baf7f233db1d935b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cec12ffe5fd4c3d8898f2426b9d35af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8fa0efa2e42b41598296fb41a626a07d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "90997baba2a24334a69485520ba3abc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94a4408a712e4736b551b2c4e58cd143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35049b5472914614a70a4d037baee119",
      "placeholder": "",
      "style": "IPY_MODEL_30870c47fba04429b3fc3d3efc02b897",
      "value": " 483/483 [00:00&lt;00:00, 5.96kB/s]"
     }
    },
    "94b84670fd8f4bb88b03a7958a3c44dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "976fde32088343fc971f19d3a579ec96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9915bdde37a641d99f1932d288cc669c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ee22e2eb08e849f082523550077ca771",
       "IPY_MODEL_af6ef94d30d44f2eb7edcdc60a8dadde",
       "IPY_MODEL_94a4408a712e4736b551b2c4e58cd143"
      ],
      "layout": "IPY_MODEL_bf2b8b550860437fa3bf10d389cadc56"
     }
    },
    "9be50ab4a01643e9b2058f75b7214c98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a36fcca0cdba428da7f005f033549d37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5473b94edc74a679a85f5fca6f41882": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af6ef94d30d44f2eb7edcdc60a8dadde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90997baba2a24334a69485520ba3abc5",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8fa0efa2e42b41598296fb41a626a07d",
      "value": 483
     }
    },
    "b085f769eb924d5b8041e4a9cd13f356": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e44b051eb1e4043bb8642e3dffedf72",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b96d4a4dfe6a4349b076d168b1ce75c3",
      "value": 29
     }
    },
    "b1e4b7aea89c46a7b70e3e8697e7a176": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b43b89c0370944889604dd768221c0e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8d2240e2f7b43819e7b160ab6801442": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b96d4a4dfe6a4349b076d168b1ce75c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b977d4dfc86d45849d1bde1062f779ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf2b8b550860437fa3bf10d389cadc56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6096e29a9f8488b9191258b9b565235": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1d28394dc9549d891242364227fdea1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4c34787373e41bcaddfb089accb2d99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d654af0b23b34490998655ef13ab3eae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8181a2c7eff049a3985b0d770cb58117",
       "IPY_MODEL_ea5690014e52463badd0cb9efbf7ea47",
       "IPY_MODEL_f16c77b245724fc380f0b1953f6c6c2b"
      ],
      "layout": "IPY_MODEL_8a7d6755fa214a00baf7f233db1d935b"
     }
    },
    "db3a628c00184181a24a63e4debaa59f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e06691ed9bb1440cb8bdfee1d031b51b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e21ac0ee07584e13b076b947917a068e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea5690014e52463badd0cb9efbf7ea47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4209d93661214168b7ace4dad9a72c5e",
      "max": 267954768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ad61d3612a64ef9b8ab23e1e9d9b808",
      "value": 267954768
     }
    },
    "ed77c58ff2a441c9babe26320823aaf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f10887089fc452c963b22e2c6583ba9",
      "placeholder": "",
      "style": "IPY_MODEL_7f0491717e8b4976bb1a672be2964c4d",
      "value": "Downloading ()okenizer_config.json: 100%"
     }
    },
    "ee22e2eb08e849f082523550077ca771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_976fde32088343fc971f19d3a579ec96",
      "placeholder": "",
      "style": "IPY_MODEL_55ff8f2830a34fbc93be9d779c07e7e9",
      "value": "Downloading ()lve/main/config.json: 100%"
     }
    },
    "efaa6e25b82a4d1b8df1df5aec1c330a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1517aa5e93f426394c327753f4add0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e06691ed9bb1440cb8bdfee1d031b51b",
      "placeholder": "",
      "style": "IPY_MODEL_d1d28394dc9549d891242364227fdea1",
      "value": " 213k/213k [00:00&lt;00:00, 3.97MB/s]"
     }
    },
    "f16c77b245724fc380f0b1953f6c6c2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f4e2dfdc9654446be174f32fa8d4d3c",
      "placeholder": "",
      "style": "IPY_MODEL_fc78cf56c9e44ec295464b7b8be3b2c7",
      "value": " 268M/268M [00:02&lt;00:00, 140MB/s]"
     }
    },
    "fc78cf56c9e44ec295464b7b8be3b2c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
